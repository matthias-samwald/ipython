{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Created on 06.03.2014\n",
      "@author: Matthias Samwald, Medical University of Vienna\n",
      "'''\n",
      "\n",
      "import itertools\n",
      "import vcf\n",
      "import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "AutoVivification = lambda: defaultdict(AutoVivification) # Autovivifying dictionary, makes it easy to create nested dictionaries without running into problems of non-existing keys.\n",
      "\n",
      "def convert_nested_dd(dd):\n",
      "    '''Converts a nested defaultdict back into a native dictionary.'''\n",
      "    return {k:convert_nested_dd(v) for k,v in dd.items()} if isinstance(dd, defaultdict) else dd\n",
      "    \n",
      "gene_definitions = AutoVivification() # captures definitions of alleles/haplotypes for several genes\n",
      "assay_rsid_coverage = dict() # mapping assays to the rsids covered by each assay\n",
      "assay_allele_coverage = AutoVivification() # mapping assays to the alleles covered by each assay\n",
      "sample_rsid_coverage = set() # the rsids observed in the genetic sample data (1000genomes)\n",
      "mapping_of_1000genomes_record_to_population = dict()\n",
      "population_to_superpopulation_mapping = dict()\n",
      "\n",
      "results_list = list() # list for capturing results of haplotype matching -- this is were the interesting data will be captured in\n",
      "\n",
      "exemplary_1000genomes_record = 'HG00096' # a random pick among the 1000genome samples -- used to check which rsids are covered in the data and which are not\n",
      "\n",
      "assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb'] = set() # this will be filled later on based on data from PharmGBK\n",
      "assay_rsid_coverage['dmet_plus'] = set(line.strip() for line in open('pharmacogenomic_test_marker_coverage/data_about_assays/dmet_plus_rsids'))\n",
      "assay_rsid_coverage['florida_stanford_chip'] = set(line.strip() for line in open('pharmacogenomic_test_marker_coverage/data_about_assays/florida_stanford_chip_rsids'))\n",
      "assay_rsid_coverage['taqman'] = set(line.strip() for line in open('pharmacogenomic_test_marker_coverage/data_about_assays/taqman_rsids'))\n",
      "assay_rsid_coverage['veracode_adme_corepanel'] = set(line.strip() for line in open('pharmacogenomic_test_marker_coverage/data_about_assays/veracode_adme_corepanel_rsids'))\n",
      "\n",
      "list_of_assays = ['hypothetical_assay_covering_all_rsids_in_pharmgkb', 'florida_stanford_chip', 'dmet_plus', 'taqman', 'veracode_adme_corepanel']\n",
      "\n",
      "haplotype_tables = dict()         \n",
      "for gene in ['CYP2C9', 'CYP2C19', 'CYP2D6', 'CYP3A5', 'DPYD', 'SLCO1B1', 'TPMT', 'UGT1A1', 'VKORC1']:\n",
      "    with open('pharmacogenomic_test_marker_coverage/gene_definitions/' + gene) as f:\n",
      "        haplotype_tables[gene] = f.read()\n",
      "\n",
      "# read haplotype table data into nested dictionary\n",
      "for gene, table in haplotype_tables.items():     \n",
      "    table = table.replace(\" [tag]\", \"\") # remove [tag] information for now...\n",
      "    first_line = True\n",
      "    for line in table.splitlines():\n",
      "        if (first_line == True):\n",
      "            header_array = line.split(\"\\t\")\n",
      "            first_line = False\n",
      "        else:\n",
      "            line_array = line.split(\"\\t\")\n",
      "            snps = {}\n",
      "    \n",
      "            rsid_start_at_column = 3    # from this column on, rsid data can be found (to the left, there is the name of the haplotype etc)\n",
      "            for index, rsid in enumerate(header_array[rsid_start_at_column:]):\n",
      "                if (rsid[0:2] == \"rs\"):    # only add if this is an rs number and not some other identifier\n",
      "                    assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb'].add(rsid)\n",
      "                    if line_array[index + rsid_start_at_column] != \"\":   # only add rsid:variant pair if there actually is an entry in the table\n",
      "                        snps[rsid] = line_array[index + rsid_start_at_column].strip()\n",
      "                \n",
      "            gene_definitions[line_array[0].strip()][line_array[2].strip()] = snps # For example: {'UGT1A1': {'*60c': {'rs4148323': 'G', 'rs1057911': 'A'}}}           \n",
      "\n",
      "gene_definitions = convert_nested_dd(gene_definitions) # convert to native dictionary\n",
      "\n",
      "# Dump parsed gene definitions to file\n",
      "with open('pharmacogenomic_test_marker_coverage/output/gene_definitions.txt', 'w') as gene_definitions_dump_file:\n",
      "    pprint.PrettyPrinter(indent=4, stream = gene_definitions_dump_file).pprint(gene_definitions)\n",
      "\n",
      "# read allele coverage data of various assays into nested dictionary\n",
      "for gene in ['CYP2C9', 'CYP2C19', 'CYP2D6', 'CYP3A5', 'DPYD', 'SLCO1B1', 'TPMT', 'UGT1A1', 'VKORC1']:\n",
      "    first_line = True\n",
      "    for line in open('pharmacogenomic_test_marker_coverage/assay_allele_coverage/' + gene):\n",
      "        if (first_line == True):\n",
      "            header_array = line.split(\"\\t\")\n",
      "            first_line = False\n",
      "        else:\n",
      "            line_array = line.split(\"\\t\")\n",
      "            for i, cell in enumerate(line_array):\n",
      "                if (i > 0):\n",
      "                    #assay_allele_coverage.append(list([gene.strip(), line_array[0].strip(), header_array[i].strip()])) # e.g., [CYP2C9, \"*2\", \"dmet_plus\"]\n",
      "                    assay_allele_coverage[header_array[i].strip()][gene.strip()][line_array[0].strip()] = cell.strip() # e.g., {'veracode_adme_corepanel': {'CYP2D6': {'*1': 'x'}}} \n",
      " \n",
      "assay_allele_coverage = convert_nested_dd(assay_allele_coverage) # convert to native dictionary\n",
      "\n",
      "# read mapping between 1000genome records and populations\n",
      "for line in open('pharmacogenomic_test_marker_coverage/1000genomes/20130606_sample_info.txt'):\n",
      "    line_array = line.split(\"\\t\")\n",
      "    mapping_of_1000genomes_record_to_population[line_array[0]] = line_array[1]    # mapping from record ID to population\n",
      "    \n",
      "# read mapping between populations and superpopulations\n",
      "for line in open('pharmacogenomic_test_marker_coverage/1000genomes/population_superpopulation_mapping.txt'):\n",
      "    line_array = line.split(\"\\t\")\n",
      "    population_to_superpopulation_mapping[line_array[0]] = line_array[2]\n",
      "         \n",
      "# for currently_processed_gene in ['CYP2C9', 'CYP2C19', 'CYP2D6', 'CYP3A5', 'DPYD', 'SLCO1B1', 'TPMT', 'UGT1A1', 'VKORC1']:\n",
      "for currently_processed_gene in ['CYP2C9', 'CYP2C19', 'CYP2D6', 'CYP3A5', 'DPYD', 'SLCO1B1', 'TPMT', 'UGT1A1', 'VKORC1']:\n",
      "    \n",
      "    print(\"Started processing data on \" + currently_processed_gene)\n",
      "    \n",
      "    thousand_genome_samples = AutoVivification() # data about samples from 1000 genomes dataset, each sample describes one maternal and one paternal set of haplotypes\n",
      "                \n",
      "    f = open('pharmacogenomic_test_marker_coverage/output/' + currently_processed_gene + '.txt', 'w')\n",
      "    output = f\n",
      "                    \n",
      "    vcf_reader = vcf.Reader(open('pharmacogenomic_test_marker_coverage/1000genomes/' + currently_processed_gene, 'r')) \n",
      "    \n",
      "    for record in vcf_reader:\n",
      "        sample_rsid_coverage.add(record.ID)\n",
      "        if record.ID in assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb']:\n",
      "            for call in record.samples:\n",
      "                thousand_genome_samples[str(call.sample)][currently_processed_gene]['maternal_haplotype']['snps'][record.ID] = call.gt_bases.split(\"|\")[0] # first variant is arbitrarily named 'maternal'\n",
      "                thousand_genome_samples[str(call.sample)][currently_processed_gene]['paternal_haplotype']['snps'][record.ID] = call.gt_bases.split(\"|\")[1] # second variant is arbitrarily named 'paternal'\n",
      "        \n",
      "                # create empty structure to hold allele information inferred later on\n",
      "                for assay in list_of_assays:\n",
      "                    for maternal_or_paternal_haplotype in ['maternal_haplotype', 'paternal_haplotype']:\n",
      "                        thousand_genome_samples[str(call.sample)][currently_processed_gene][maternal_or_paternal_haplotype]['allele'][assay] = set()\n",
      "    \n",
      "    thousand_genome_samples = convert_nested_dd(thousand_genome_samples) # convert to native dictionary\n",
      "    \n",
      "    rsids_in_1000genomes = set(thousand_genome_samples[exemplary_1000genomes_record][currently_processed_gene]['maternal_haplotype']['snps'].keys())\n",
      "    \n",
      "    print(''' \n",
      "\n",
      "Task 1:\n",
      "For different lists of SNPs covered by different assays, group alleles into indistinguishable allels.    \n",
      "TODO: Compare that to alleles claimed to be discoverable by manufacturer.\n",
      "\n",
      "''', file = output)\n",
      "        \n",
      "    for assay, covered_rsids in assay_rsid_coverage.items():\n",
      "        print(\"\\n\\n** ASSAY:\", assay, \"**\", file = output)\n",
      "        haplotypes = gene_definitions[currently_processed_gene]\n",
      "        \n",
      "        #print(\"GENE:\", gene)\n",
      "        count_overlapping = 0\n",
      "        overlapping_haplotype_sets = list()\n",
      "        # generate 'pruned' versions of the haplotypes that only contain rsids/SNPs covered by the specific assay (i.e., the intersection of rsids in the PharmGKB table and rsids covered by the assay), AS WELL AS BY 1000genomes DATASETS!\n",
      "        pruned_haplotypes = dict()\n",
      "        for haplotype_id, haplotype in haplotypes.items():\n",
      "            pruned_haplotypes[haplotype_id] = {rsid: haplotype[rsid] for rsid in set(covered_rsids & haplotype.keys() & rsids_in_1000genomes)}\n",
      "            \n",
      "        # check all combinations of these pruned haplotype definitions for overlaps\n",
      "        for haplotype_id_1, haplotype_id_2 in itertools.combinations(pruned_haplotypes, 2):   \n",
      "            haplotype_1_snps = set(pruned_haplotypes[haplotype_id_1].items())\n",
      "            haplotype_2_snps = set(pruned_haplotypes[haplotype_id_2].items()) \n",
      "            if haplotype_1_snps.issubset(haplotype_2_snps):\n",
      "                #count_overlapping += 1\n",
      "                found_existing_set_containing_at_least_one_of_the_overlapping_snps = False\n",
      "                \n",
      "                # iterate through list of overlapping haplotypes already found, if one haplotype_id in the overlapping pair is already part of a set of overlapping haplotypes, add the pair to this set\n",
      "                for i, val in enumerate(overlapping_haplotype_sets):\n",
      "                    if (haplotype_id_1 in val) or (haplotype_id_2 in val):\n",
      "                        overlapping_haplotype_sets[i].add(haplotype_id_1)\n",
      "                        overlapping_haplotype_sets[i].add(haplotype_id_2)\n",
      "                        found_existing_set_containing_at_least_one_of_the_overlapping_snps = True\n",
      "                if not found_existing_set_containing_at_least_one_of_the_overlapping_snps:\n",
      "                    overlapping_haplotype_sets.append({haplotype_id_1, haplotype_id_2})\n",
      "                    \n",
      "        print(len(overlapping_haplotype_sets), \"set(s) of mutually indistinguishable haplotypes: \", overlapping_haplotype_sets, file = output)\n",
      "        print(len(pruned_haplotypes[haplotype_id_1].keys()), \"rsids were used to define haplotypes for this gene\", file = output)\n",
      "        \n",
      "        \n",
      "        # disabled the code below -- until now, we did not constraint haplotypes by presence in 1000genomes as well -- but now we do.\n",
      "        '''\n",
      "        rsids_covered_by_assay_and_found_in_samples = set(pruned_haplotypes[haplotype_id_1].keys()).intersection(rsids_in_1000genomes)\n",
      "        print(len(rsids_covered_by_assay_and_found_in_samples), \"out of these rsids are present in the 1000genomes samples:\", rsids_covered_by_assay_and_found_in_samples, file = output)\n",
      "        rsids_covered_by_assay_but_not_found_in_samples = set(pruned_haplotypes[haplotype_id_1].keys()).difference(rsids_in_1000genomes)   \n",
      "        print(len(rsids_covered_by_assay_but_not_found_in_samples), \"out of these rsids are not present in the 1000genomes samples:\", rsids_covered_by_assay_but_not_found_in_samples, \"\\n\", file = output)\n",
      "        '''\n",
      "            \n",
      "    print(''' \n",
      "\n",
      "Task 2:\n",
      "For different lists of SNPs covered by different assays, calculate how many samples in 1000genomes would be assigned an allele \n",
      "that actually does not match the 'correct' allele ('correct' allele = the allele inferred based on 'hypothetical_assay_covering_all_rsids_in_pharmgkb'). \n",
      "TODO: Also generate statistics on inferred alleles, ethnicities etc.\n",
      "\n",
      "''', file = output)\n",
      "    \n",
      "    # print(gene_definitions['VKORC1']['*1'])\n",
      "    # print(thousand_genome_samples['HG00096']['VKORC1']['paternal_haplotype']['snps'])\n",
      "    \n",
      "    # for each type of assay\n",
      "    for assay, covered_rsids in assay_rsid_coverage.items():\n",
      "        # iterate through all 1000genome samples\n",
      "        for sample, sample_data in thousand_genome_samples.items():\n",
      "            # iterate through genes of each sample\n",
      "            for gene, gene_data in sample_data.items():\n",
      "                # generate 'pruned' versions of the PharmGKB haplotypes based on the limited set of rsids that can be obseverd by the assay\n",
      "                # TODO: the current implemntation is a bit inefficient, since we are redundantly generating pruned haplotype definitions for each new sample...\n",
      "                pruned_haplotypes = dict()\n",
      "                for haplotype_id, haplotype in gene_definitions[gene].items():\n",
      "                    pruned_haplotypes[haplotype_id] = {rsid: haplotype[rsid] for rsid in set(covered_rsids & haplotype.keys() & gene_data['maternal_haplotype']['snps'].keys())}\n",
      "                # skip and print message if assay has no rsids of this gene at all (which probably means that the assay was not designed to test for this gene at all)\n",
      "                if len(pruned_haplotypes) == 0:\n",
      "                    print(\"It seems like this assay covers no markers of this gene at all; skipping...\", file = output)\n",
      "                    continue\n",
      "                # print(pruned_haplotypes)\n",
      "                for maternal_or_paternal_haplotype in ['maternal_haplotype', 'paternal_haplotype']:\n",
      "                    # iterate through all the pruned haplotypes and see if they are subsets of the haplotype found in the sample\n",
      "                    for pruned_haplotype_id in pruned_haplotypes:\n",
      "                        if set(pruned_haplotypes[pruned_haplotype_id].items()).issubset(set(gene_data[maternal_or_paternal_haplotype]['snps'].items())):\n",
      "                            assay_allele_coverage_status = assay_allele_coverage.get(assay, {}).get(gene, {}).get(pruned_haplotype_id, \"\")\n",
      "                            if (assay_allele_coverage_status != \"\") or assay == 'hypothetical_assay_covering_all_rsids_in_pharmgkb':   # only call allele if it is among the callable alleles for this assay, or if we are examining the hypothetical assay\n",
      "                                #print(maternal_or_paternal_haplotype, \"match:\", pruned_haplotype_id, file = output)\n",
      "                                thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['allele'][assay].add(pruned_haplotype_id)\n",
      "    \n",
      "                                \n",
      "                                # print('Information on coverage of this allele by this assay:', assay_allele_coverage_status, file = output)\n",
      "                                # iterate through the variants expected in the full (unpruned) definition of the matching haplotype, and flag any mismatches with the data in the sample\n",
      "                                '''\n",
      "                                for rsid, variant in gene_definitions[gene][pruned_haplotype_id].items():\n",
      "                                    if gene_data[maternal_or_paternal_haplotype].get(rsid, False) and gene_data[maternal_or_paternal_haplotype][rsid] != variant:\n",
      "                                        print(\"Mismatch found for\", rsid, \"- based on haplotype definition expected\", variant, \"but found\", gene_data[maternal_or_paternal_haplotype][rsid], file = output)                  \n",
      "                              \n",
      "                        else:\n",
      "                            if pruned_haplotype_id[0:3] == \"*1\":\n",
      "                                print(\"Did not match wild-type, here are the allele definition for this assay and the data we see in the sample:\")\n",
      "                                print(pruned_haplotypes[pruned_haplotype_id])\n",
      "                                print(gene_data[maternal_or_paternal_haplotype]['snps'])\n",
      "                                  '''\n",
      "    print('''\n",
      "Task 3:\n",
      "\n",
      "Generate statistics\n",
      "\n",
      "''', file = output)\n",
      "                                \n",
      "    snp_frequency_data = AutoVivification()  #    for example: {  'rs1057910': {   'count_in_gene_definitions': {'A': 32, 'C': 2},\n",
      "                                            #                                     'count_in_population_sample': {'A': 2091, 'C': 93}}}\n",
      "    for haplotype_id in gene_definitions[currently_processed_gene]:\n",
      "        for rsid in gene_definitions[currently_processed_gene][haplotype_id]:\n",
      "            # this is quite unelegant because of the way the autovivification dictionary works (inexistant values do not default to 0)\n",
      "            if isinstance(snp_frequency_data[rsid]['count_in_gene_definitions'][gene_definitions[currently_processed_gene][haplotype_id][rsid]], int):\n",
      "                snp_frequency_data[rsid]['count_in_gene_definitions'][gene_definitions[currently_processed_gene][haplotype_id][rsid]] += 1\n",
      "            else:\n",
      "                snp_frequency_data[rsid]['count_in_gene_definitions'][gene_definitions[currently_processed_gene][haplotype_id][rsid]] = 1\n",
      "             \n",
      "    for sample in thousand_genome_samples:\n",
      "        for gene in thousand_genome_samples[sample]:\n",
      "            for maternal_or_paternal_haplotype in ['maternal_haplotype', 'paternal_haplotype']:\n",
      "                for rsid in thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['snps']:\n",
      "                    if isinstance(snp_frequency_data[rsid]['count_in_population_sample'][thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['snps'][rsid]], int):\n",
      "                        snp_frequency_data[rsid]['count_in_population_sample'][thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['snps'][rsid]] += 1\n",
      "                    else:\n",
      "                        snp_frequency_data[rsid]['count_in_population_sample'][thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['snps'][rsid]] = 1\n",
      "    \n",
      "    snp_frequency_data = convert_nested_dd(snp_frequency_data)                                                                                                        \n",
      "    \n",
      "    \n",
      "    '''\n",
      "    print(\"The following SNP variants are used in a gene definition, but were never observed in a sample, even though their rs number was tested for at least one sample (this can also be a hint for strand orientation mismatch):\", file = output)\n",
      "    for rsid in assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb']:\n",
      "        for snp_variant in snp_frequency_data[rsid]['count_in_gene_definitions']:\n",
      "            if snp_frequency_data[rsid].get('count_in_population_sample'):\n",
      "                if snp_frequency_data[rsid].get('count_in_population_sample').get(snp_variant, 0) == 0:\n",
      "                    print(rsid, snp_variant, file = output)\n",
      "    print(\"---------\")\n",
      "    '''\n",
      "    \n",
      "    \n",
      "    # show alleles called \n",
      "    print('''\n",
      "    \n",
      "    SNP variant counts in gene definitions and in sample data.\n",
      "    \n",
      "    ''', file = output)\n",
      "    \n",
      "    \n",
      "    \n",
      "    # display header row\n",
      "    output_line = \"superpopulation\" + \"\\t\" + \"sample\" + \"\\t\" + \"gene\" + \"\\t\" + \"maternal_or_paternal_haplotype\"\n",
      "    for assay in list_of_assays:\n",
      "        output_line = output_line + \"\\t\" + assay + \"\\t Bogus calls from \" + assay \n",
      "    print(output_line, file = output)    \n",
      "    \n",
      "    # display data     \n",
      "    for sample in thousand_genome_samples:\n",
      "        result_row_as_dictionary = dict()\n",
      "        for maternal_or_paternal_haplotype in ['maternal_haplotype', 'paternal_haplotype']:\n",
      "            result_row_as_dictionary['superpopulation'] = population_to_superpopulation_mapping[mapping_of_1000genomes_record_to_population[sample]]\n",
      "            result_row_as_dictionary['sample'] = sample\n",
      "            result_row_as_dictionary['gene'] = currently_processed_gene \n",
      "            result_row_as_dictionary['maternal_or_paternal_haplotype'] = maternal_or_paternal_haplotype\n",
      "            for assay in list_of_assays:\n",
      "                result_row_as_dictionary['haplotype_calls_' + assay] = thousand_genome_samples[sample][currently_processed_gene][maternal_or_paternal_haplotype]['allele'][assay]\n",
      "                result_row_as_dictionary['bogus_haplotype_calls_' + assay] = thousand_genome_samples[sample][currently_processed_gene][maternal_or_paternal_haplotype]['allele'][assay].difference(thousand_genome_samples[sample][currently_processed_gene][maternal_or_paternal_haplotype]['allele']['hypothetical_assay_covering_all_rsids_in_pharmgkb'])\n",
      "            print(result_row_as_dictionary, file = output)\n",
      "            #for assay in thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['allele']:\n",
      "            # print(sample, gene, maternal_or_paternal_haplotype, assay, thousand_genome_samples[sample][gene][maternal_or_paternal_haplotype]['allele'][assay])\n",
      "        results_list.append(result_row_as_dictionary)\n",
      "    pp = pprint.PrettyPrinter(indent=4, stream = output)\n",
      "    pp.pprint(snp_frequency_data)\n",
      "    # pp.pprint(thousand_genome_samples)\n",
      "\n",
      "    f.close()                                \n",
      "\n",
      "\n",
      "with open('pharmacogenomic_test_marker_coverage/output/overview.txt', 'w') as f:\n",
      "    print(\"Started generating overview document\")\n",
      "    print(len(assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb']), \n",
      "          \"rsids in hypothetical_assay_covering_all_rsids_in_pharmgkb:\", file = f)\n",
      "    print(assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb'], file = f)\n",
      "    \n",
      "    rsids_in_pharmgkb_but_not_in_1000genomes = set(assay_rsid_coverage['hypothetical_assay_covering_all_rsids_in_pharmgkb']).difference(sample_rsid_coverage)\n",
      "    print(\"\\n\", len(rsids_in_pharmgkb_but_not_in_1000genomes), \n",
      "          \"rsids in hypothetical_assay_covering_all_rsids_in_pharmgkb that are not found in 1000genomes data:\", file = f)\n",
      "    print(rsids_in_pharmgkb_but_not_in_1000genomes, file = f)\n",
      "    \n",
      "    \n",
      "'''\n",
      "rsids_covered_by_assay_but_not_found_in_samples = covered_rsids - set(thousand_genome_samples[exemplary_1000genomes_record][currently_processed_gene]['maternal_haplotype']['snps'].keys())    \n",
      "print(\"\\nThe following\", len(rsids_covered_by_assay_but_not_found_in_samples), \"rsids are covered by this assay, but are not present in the 1000genomes samples:\", rsids_covered_by_assay_but_not_found_in_samples, file = output)\n",
      "'''        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Started processing data on CYP2C9\n",
        "Started processing data on CYP2C19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on CYP3A5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on DPYD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on SLCO1B1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on TPMT"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on UGT1A1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started processing data on VKORC1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Started generating overview document"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "'\\nrsids_covered_by_assay_but_not_found_in_samples = covered_rsids - set(thousand_genome_samples[exemplary_1000genomes_record][currently_processed_gene][\\'maternal_haplotype\\'][\\'snps\\'].keys())    \\nprint(\"\\nThe following\", len(rsids_covered_by_assay_but_not_found_in_samples), \"rsids are covered by this assay, but are not present in the 1000genomes samples:\", rsids_covered_by_assay_but_not_found_in_samples, file = output)\\n'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_list[0].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "dict_keys(['superpopulation', 'bogus_haplotype_calls_florida_stanford_chip', 'haplotype_calls_dmet_plus', 'bogus_haplotype_calls_taqman', 'sample', 'haplotype_calls_hypothetical_assay_covering_all_rsids_in_pharmgkb', 'bogus_haplotype_calls_hypothetical_assay_covering_all_rsids_in_pharmgkb', 'maternal_or_paternal_haplotype', 'haplotype_calls_taqman', 'gene', 'bogus_haplotype_calls_veracode_adme_corepanel', 'haplotype_calls_florida_stanford_chip', 'haplotype_calls_veracode_adme_corepanel', 'bogus_haplotype_calls_dmet_plus'])"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "{'bogus_haplotype_calls_dmet_plus': set(),\n",
        " 'bogus_haplotype_calls_florida_stanford_chip': set(),\n",
        " 'bogus_haplotype_calls_hypothetical_assay_covering_all_rsids_in_pharmgkb': set(),\n",
        " 'bogus_haplotype_calls_taqman': {'*13'},\n",
        " 'bogus_haplotype_calls_veracode_adme_corepanel': {'*13'},\n",
        " 'gene': 'CYP2C9',\n",
        " 'haplotype_calls_dmet_plus': {'*1',\n",
        "  '*10',\n",
        "  '*14',\n",
        "  '*15',\n",
        "  '*16',\n",
        "  '*25',\n",
        "  '*4',\n",
        "  '*6'},\n",
        " 'haplotype_calls_florida_stanford_chip': {'*1'},\n",
        " 'haplotype_calls_hypothetical_assay_covering_all_rsids_in_pharmgkb': {'*1',\n",
        "  '*10',\n",
        "  '*14',\n",
        "  '*15',\n",
        "  '*16',\n",
        "  '*17',\n",
        "  '*19',\n",
        "  '*20',\n",
        "  '*21',\n",
        "  '*22',\n",
        "  '*23',\n",
        "  '*25',\n",
        "  '*26',\n",
        "  '*27',\n",
        "  '*28',\n",
        "  '*29',\n",
        "  '*30',\n",
        "  '*32',\n",
        "  '*33',\n",
        "  '*34',\n",
        "  '*4',\n",
        "  '*6',\n",
        "  '*7'},\n",
        " 'haplotype_calls_taqman': {'*1', '*10', '*13', '*15', '*25', '*27', '*6'},\n",
        " 'haplotype_calls_veracode_adme_corepanel': {'*1',\n",
        "  '*10',\n",
        "  '*13',\n",
        "  '*15',\n",
        "  '*25',\n",
        "  '*4',\n",
        "  '*6'},\n",
        " 'maternal_or_paternal_haplotype': 'paternal_haplotype',\n",
        " 'sample': 'NA18962',\n",
        " 'superpopulation': 'ASN'}"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: Take no-call into consideratoin\n",
      "print(\"Gene\\tHaplotype\\tFLOR\\tTAQM\\tDMET\\tVERA\\tMean\")\n",
      "\n",
      "for gene in gene_definitions.keys():\n",
      "    for haplotype in gene_definitions[gene].keys():\n",
      "        flor_bogus_count = 0\n",
      "        taqm_bogus_count = 0\n",
      "        vera_bogus_count = 0\n",
      "        dmet_bogus_count = 0\n",
      "        for row in results_list:\n",
      "            if (row['gene'] == gene):\n",
      "                #print(row['bogus_haplotype_calls_florida_stanford_chip'])\n",
      "                if haplotype in row['bogus_haplotype_calls_florida_stanford_chip']:\n",
      "                    flor_bogus_count += 1\n",
      "                if haplotype in row['bogus_haplotype_calls_taqman']:\n",
      "                    taqm_bogus_count += 1\n",
      "                if haplotype in row['bogus_haplotype_calls_dmet_plus']:\n",
      "                    dmet_bogus_count += 1\n",
      "                if haplotype in row['bogus_haplotype_calls_veracode_adme_corepanel']:\n",
      "                    vera_bogus_count += 1\n",
      "        total_bogus_calls_for_all_assays = flor_bogus_count + taqm_bogus_count + vera_bogus_count + dmet_bogus_count\n",
      "        if total_bogus_calls_for_all_assays > 0 : \n",
      "            print(gene, haplotype, flor_bogus_count, taqm_bogus_count, dmet_bogus_count, vera_bogus_count, (total_bogus_calls_for_all_assays) / 4, sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Gene\tHaplotype\tFLOR\tTAQM\tDMET\tVERA\tMean\n",
        "VKORC1\t*1\t153\t0\t0\t505\t164.5\n",
        "VKORC1\t*3\t2\t0\t0\t0\t0.5\n",
        "CYP2C19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*10\t0\t0\t573\t0\t143.25\n",
        "CYP2C19\t*12\t0\t627\t573\t627\t456.75\n",
        "CYP2C19\t*13\t0\t0\t4\t0\t1.0\n",
        "CYP2C19\t*14\t0\t0\t573\t0\t143.25\n",
        "CYP2C19\t*15\t0\t0\t4\t0\t1.0\n",
        "CYP2C19\t*17\t176\t176\t175\t176\t175.75\n",
        "CYP2C19\t*5A\t689\t689\t44\t689\t527.75\n",
        "CYP2C19\t*4A\t2\t2\t2\t2\t2.0\n",
        "CYP2C19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*2D\t210\t210\t191\t210\t205.25\n",
        "CYP2C19\t*1\t689\t689\t44\t689\t527.75\n",
        "CYP2C19\t*2\t210\t210\t0\t210\t157.5\n",
        "CYP2C19\t*3\t15\t15\t0\t15\t11.25\n",
        "CYP2C19\t*4\t2\t2\t0\t2\t1.5\n",
        "CYP2C19\t*5\t689\t689\t44\t689\t527.75\n",
        "CYP2C19\t*6\t627\t627\t573\t627\t613.5\n",
        "CYP2C19\t*7\t0\t689\t44\t689\t355.5\n",
        "CYP2C19\t*9\t0\t0\t2\t0\t0.5\n",
        "CYP2C19\t*2C\t206\t206\t187\t206\t201.25\n",
        "CYP2C19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*2B\t210\t210\t19\t210\t162.25\n",
        "CYP2C19\t*5B\t627\t627\t573\t627\t613.5\n",
        "CYP2C19\t*2A\t210\t210\t0\t210\t157.5\n",
        "CYP2C19\t*3B\t2\t2\t2\t2\t2.0\n",
        "CYP2C19\t*3A\t15\t15\t15\t15\t15.0\n",
        "TPMT"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*24\t0\t0\t4\t0\t1.0\n",
        "TPMT\t*1\t685\t685\t427\t685\t620.5\n",
        "TPMT\t*2\t685\t685\t427\t685\t620.5\n",
        "TPMT\t*8\t0\t685\t427\t685\t449.25\n",
        "TPMT"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*3B\t685\t685\t427\t685\t620.5\n",
        "TPMT\t*3C\t685\t685\t427\t685\t620.5\n",
        "TPMT\t*3A\t0\t0\t0\t685\t171.25\n",
        "CYP3A5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*3E\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*1\t26\t0\t0\t0\t6.5\n",
        "CYP3A5\t*3\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3D\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3F\t755\t755\t0\t755\t566.25\n",
        "CYP3A5\t*3G\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3C\t15\t15\t0\t15\t11.25\n",
        "CYP3A5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*3B\t750\t750\t0\t750\t562.5\n",
        "CYP3A5\t*3L\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3I\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3J\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3K\t15\t15\t0\t15\t11.25\n",
        "CYP3A5\t*3H\t15\t15\t0\t15\t11.25\n",
        "CYP2C9\t*10\t0\t2\t11\t2\t3.75\n",
        "CYP2C9\t*13\t0\t917\t0\t917\t458.5\n",
        "CYP2C9\t*14\t0\t0\t11\t0\t2.75\n",
        "CYP2C9\t*16\t0\t0\t11\t0\t2.75\n",
        "CYP2C9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*25\t0\t2\t11\t2\t3.75\n",
        "CYP2C9\t*27\t0\t2\t0\t0\t0.5\n",
        "CYP2C9\t*15\t0\t2\t11\t2\t3.75\n",
        "CYP2C9\t*1\t39\t2\t11\t2\t13.5\n",
        "CYP2C9\t*3\t43\t43\t0\t43\t32.25\n",
        "CYP2C9\t*4\t0\t0\t11\t2\t3.25\n",
        "CYP2C9\t*6\t0\t2\t11\t2\t3.75\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*44\t0\t283\t26\t271\t145.0\n",
        "CYP2D6\t*42\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*41\t1\t1\t1\t1\t1.0\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*38\t0\t283\t26\t271\t145.0\n",
        "CYP2D6\t*56A\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*56B\t0\t5\t0\t4\t2.25\n",
        "CYP2D6\t*4N\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*4L\t75\t75\t75\t75\t75.0\n",
        "CYP2D6\t*4K\t121\t121\t0\t121\t90.75\n",
        "CYP2D6\t*4J\t121\t121\t0\t121\t90.75\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*4G\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*4F\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*4E\t75\t75\t75\t75\t75.0\n",
        "CYP2D6\t*4H\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*4C\t75\t75\t75\t75\t75.0\n",
        "CYP2D6\t*4B\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*4A\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*10B\t5\t5\t0\t4\t3.5\n",
        "CYP2D6\t*11\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*4D\t75\t75\t75\t75\t75.0\n",
        "CYP2D6\t*10A\t5\t5\t0\t4\t3.5\n",
        "CYP2D6\t*14B\t0\t493\t40\t481\t253.5\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*14A\t0\t158\t0\t157\t78.75\n",
        "CYP2D6\t*10D\t5\t5\t0\t4\t3.5\n",
        "CYP2D6\t*21\t0\t0\t40\t481\t130.25\n",
        "CYP2D6\t*20\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*21B\t0\t0\t40\t481\t130.25\n",
        "CYP2D6\t*21A\t0\t0\t40\t481\t130.25\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*1\t283\t283\t26\t271\t215.75\n",
        "CYP2D6\t*4\t46\t46\t46\t46\t46.0\n",
        "CYP2D6\t*6\t1\t1\t0\t1\t0.75\n",
        "CYP2D6\t*7\t283\t283\t26\t271\t215.75\n",
        "CYP2D6\t*8\t0\t493\t40\t481\t253.5\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*10\t5\t5\t0\t4\t3.5\n",
        "CYP2D6\t*12\t493\t493\t40\t481\t376.75\n",
        "CYP2D6\t*14\t0\t158\t0\t157\t78.75\n",
        "CYP2D6\t*15\t0\t283\t26\t271\t145.0\n",
        "CYP2D6\t*18\t0\t283\t26\t271\t145.0\n",
        "CYP2D6\t*19\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*2\t0\t493\t0\t481\t243.5\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*56\t0\t493\t40\t481\t253.5\n",
        "CYP2D6\t*6D\t1\t1\t0\t1\t0.75\n",
        "CYP2D6\t*6A\t1\t1\t0\t1\t0.75\n",
        "CYP2D6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*6C\t10\t10\t0\t10\t7.5\n",
        "CYP2D6\t*6B\t1\t1\t0\t1\t0.75\n",
        "CYP2D6\t*2A\t0\t493\t0\t481\t243.5\n",
        "CYP2D6\t*9\t0\t669\t412\t2\t270.75\n",
        "SLCO1B1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*10\t0\t315\t2\t315\t158.0\n",
        "SLCO1B1\t*11\t0\t315\t2\t315\t158.0\n",
        "SLCO1B1\t*12\t0\t0\t0\t315\t78.75\n",
        "SLCO1B1\t*13\t0\t315\t0\t315\t157.5\n",
        "SLCO1B1\t*17\t137\t0\t0\t0\t34.25\n",
        "SLCO1B1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*21\t237\t0\t0\t0\t59.25\n",
        "SLCO1B1\t*1\t315\t315\t2\t315\t236.75\n",
        "SLCO1B1\t*2\t0\t315\t2\t315\t158.0\n",
        "SLCO1B1\t*3\t0\t315\t2\t315\t158.0\n",
        "SLCO1B1\t*5\t0\t18\t0\t18\t9.0\n",
        "SLCO1B1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*6\t0\t315\t2\t315\t158.0\n",
        "SLCO1B1\t*7\t0\t0\t2\t0\t0.5\n",
        "SLCO1B1\t*8\t0\t0\t2\t0\t0.5\n",
        "SLCO1B1\t*1B\t285\t355\t6\t355\t250.25\n",
        "DPYD\t*10\t0\t268\t268\t268\t201.0\n",
        "DPYD\t*1\t268\t268\t268\t268\t268.0\n",
        "DPYD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*3\t0\t0\t268\t0\t67.0\n",
        "DPYD\t*4\t0\t0\t268\t0\t67.0\n",
        "DPYD\t*11\t0\t0\t268\t0\t67.0\n",
        "DPYD\t*8\t0\t268\t268\t268\t201.0\n",
        "DPYD\t*9A\t0\t268\t268\t268\t201.0\n",
        "DPYD\t*9B\t0\t268\t268\t268\t201.0\n",
        "DPYD\t*7\t0\t268\t268\t268\t201.0\n",
        "DPYD\t*2A\t268\t268\t268\t268\t268.0\n",
        "DPYD\t*13\t0\t0\t268\t0\t67.0\n",
        "DPYD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\t*2B\t0\t0\t876\t0\t219.0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: Take no-call into consideration\n",
      "\n",
      "for gene in gene_definitions.keys():\n",
      "    superpopulation_bogus_calls = {'EUR': 0, 'AFR': 0, 'AMR': 0, 'ASN': 0, 'SAN': 0}\n",
      "    superpopulation_no_calls = {'EUR': 0, 'AFR': 0, 'AMR': 0, 'ASN': 0, 'SAN': 0}\n",
      "    superpopulation_count = {'EUR': 0, 'AFR': 0, 'AMR': 0, 'ASN': 0, 'SAN': 0}\n",
      "    for row in results_list:\n",
      "        if (row['gene'] == gene):\n",
      "            total_nocalls_for_all_assay = 0\n",
      "            if len(row['haplotype_calls_florida_stanford_chip']) == 0:\n",
      "                total_nocalls_for_all_assay += 1\n",
      "            if len(row['haplotype_calls_taqman']) == 0:\n",
      "                total_nocalls_for_all_assay += 1\n",
      "            if len(row['haplotype_calls_dmet_plus']) == 0:\n",
      "                total_nocalls_for_all_assay += 1\n",
      "            if len(row['haplotype_calls_veracode_adme_corepanel']) == 0:\n",
      "                total_nocalls_for_all_assay += 1\n",
      "            if total_nocalls_for_all_assay > 0:\n",
      "                superpopulation_no_calls[row['superpopulation']] += total_nocalls_for_all_assay\n",
      "            \n",
      "            total_bogus_calls_for_all_assays = len(row['bogus_haplotype_calls_florida_stanford_chip']) +\\\n",
      "                len(row['bogus_haplotype_calls_taqman']) +\\\n",
      "                len(row['bogus_haplotype_calls_dmet_plus']) +\\\n",
      "                len(row['bogus_haplotype_calls_veracode_adme_corepanel'])\n",
      "            superpopulation_count[row['superpopulation']] += 1\n",
      "            if total_bogus_calls_for_all_assays > 0:\n",
      "                superpopulation_bogus_calls[row['superpopulation']] += total_bogus_calls_for_all_assays\n",
      "    print(gene)\n",
      "    for superpopulation in superpopulation_count.keys():\n",
      "        if superpopulation_count[superpopulation] > 0:\n",
      "            print (superpopulation, \n",
      "                   'bogus calls:\\t',\n",
      "                   superpopulation_bogus_calls[superpopulation], '/', \n",
      "                   superpopulation_count[superpopulation], '/ 4 =\\t', \n",
      "                   '{0:.2f}'.format((superpopulation_bogus_calls[superpopulation] / superpopulation_count[superpopulation]) / 4),\n",
      "                   '\\tno calls:',\n",
      "                   superpopulation_no_calls[superpopulation], '/',\n",
      "                   superpopulation_count[superpopulation], '/ 4 =\\t', \n",
      "                   '{0:.2%}'.format((superpopulation_no_calls[superpopulation] / superpopulation_count[superpopulation]) / 4),\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "VKORC1\n",
        "AFR bogus calls:\t 209 / 246 / 4 =\t 0.21 \tno calls: 299 / 246 / 4 =\t 30.39%\n",
        "EUR bogus calls:\t 298 / 379 / 4 =\t 0.20 \tno calls: 529 / 379 / 4 =\t 34.89%\n",
        "AMR bogus calls:\t 127 / 181 / 4 =\t 0.18 \tno calls: 257 / 181 / 4 =\t 35.50%\n",
        "ASN bogus calls:\t 26 / 286 / 4 =\t 0.02 \tno calls: 546 / 286 / 4 =\t 47.73%\n",
        "CYP2C19\n",
        "AFR bogus calls:\t 4232 / 246 / 4 =\t 4.30 \tno calls: 0 / 246 / 4 =\t 0.00%\n",
        "EUR bogus calls:\t 6507 / 379 / 4 =\t 4.29 \tno calls: 1 / 379 / 4 =\t 0.07%\n",
        "AMR bogus calls:\t 3497 / 181 / 4 =\t 4.83 \tno calls: 0 / 181 / 4 =\t 0.00%\n",
        "ASN bogus calls:\t 5775 / 286 / 4 =\t 5.05 \tno calls: 0 / 286 / 4 =\t 0.00%\n",
        "TPMT\n",
        "AFR bogus calls:\t 3743 / 246 / 4 =\t 3.80 \tno calls: 49 / 246 / 4 =\t 4.98%\n",
        "EUR bogus calls:\t 3975 / 379 / 4 =\t 2.62 \tno calls: 89 / 379 / 4 =\t 5.87%\n",
        "AMR bogus calls:\t 2236 / 181 / 4 =\t 3.09 \tno calls: 48 / 181 / 4 =\t 6.63%\n",
        "ASN bogus calls:\t 2460 / 286 / 4 =\t 2.15 \tno calls: 68 / 286 / 4 =\t 5.94%\n",
        "UGT1A1\n",
        "AFR bogus calls:\t 0 / 246 / 4 =\t 0.00 \tno calls: 984 / 246 / 4 =\t 100.00%\n",
        "EUR bogus calls:\t 0 / 379 / 4 =\t 0.00 \tno calls: 1516 / 379 / 4 =\t 100.00%\n",
        "AMR bogus calls:\t 0 / 181 / 4 =\t 0.00 \tno calls: 724 / 181 / 4 =\t 100.00%\n",
        "ASN bogus calls:\t 0 / 286 / 4 =\t 0.00 \tno calls: 1144 / 286 / 4 =\t 100.00%\n",
        "CYP3A5\n",
        "AFR bogus calls:\t 314 / 246 / 4 =\t 0.32 \tno calls: 4 / 246 / 4 =\t 0.41%\n",
        "EUR bogus calls:\t 2394 / 379 / 4 =\t 1.58 \tno calls: 2 / 379 / 4 =\t 0.13%\n",
        "AMR bogus calls:\t 927 / 181 / 4 =\t 1.28 \tno calls: 0 / 181 / 4 =\t 0.00%\n",
        "ASN bogus calls:\t 1356 / 286 / 4 =\t 1.19 \tno calls: 0 / 286 / 4 =\t 0.00%\n",
        "CYP2C9\n",
        "AFR bogus calls:\t 498 / 246 / 4 =\t 0.51 \tno calls: 1 / 246 / 4 =\t 0.10%\n",
        "EUR bogus calls:\t 688 / 379 / 4 =\t 0.45 \tno calls: 20 / 379 / 4 =\t 1.32%\n",
        "AMR bogus calls:\t 332 / 181 / 4 =\t 0.46 \tno calls: 7 / 181 / 4 =\t 0.97%\n",
        "ASN bogus calls:\t 596 / 286 / 4 =\t 0.52 \tno calls: 15 / 286 / 4 =\t 1.31%\n",
        "CYP2D6\n",
        "AFR bogus calls:\t 5319 / 246 / 4 =\t 5.41 \tno calls: 59 / 246 / 4 =\t 6.00%\n",
        "EUR bogus calls:\t 8409 / 379 / 4 =\t 5.55 \tno calls: 8 / 379 / 4 =\t 0.53%\n",
        "AMR bogus calls:\t 4435 / 181 / 4 =\t 6.13 \tno calls: 3 / 181 / 4 =\t 0.41%\n",
        "ASN bogus calls:\t 4051 / 286 / 4 =\t 3.54 \tno calls: 4 / 286 / 4 =\t 0.35%\n",
        "SLCO1B1\n",
        "AFR bogus calls:\t 814 / 246 / 4 =\t 0.83 \tno calls: 215 / 246 / 4 =\t 21.85%\n",
        "EUR bogus calls:\t 2973 / 379 / 4 =\t 1.96 \tno calls: 515 / 379 / 4 =\t 33.97%\n",
        "AMR bogus calls:\t 1229 / 181 / 4 =\t 1.70 \tno calls: 206 / 181 / 4 =\t 28.45%\n",
        "ASN bogus calls:\t 1451 / 286 / 4 =\t 1.27 \tno calls: 295 / 286 / 4 =\t 25.79%\n",
        "DPYD"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AFR bogus calls:\t 1684 / 246 / 4 =\t 1.71 \tno calls: 0 / 246 / 4 =\t 0.00%\n",
        "EUR bogus calls:\t 2477 / 379 / 4 =\t 1.63 \tno calls: 0 / 379 / 4 =\t 0.00%\n",
        "AMR bogus calls:\t 1426 / 181 / 4 =\t 1.97 \tno calls: 0 / 181 / 4 =\t 0.00%\n",
        "ASN bogus calls:\t 2525 / 286 / 4 =\t 2.21 \tno calls: 0 / 286 / 4 =\t 0.00%\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}